# CS492(F), Computational Learning Theory, Fall 2021, KAIST

This is a webpage of the course "CS492(F) Computational Learning Theory", which is offered at the KAIST CS department in the fall of 2021. The webpage will contain links to course-related materials and announcements.

The goal of this course is to expose students to the mathematical techniques for proving the guarantees of machine-learning algorithms. The main theme of the course is to find a mathematical guarantee of inductive generalisation used by machine learning algorithms: when a learning algorithm returns a classifier based on a given training data, what can we say about the real error of the classifier mathematically? We will study concepts designed to measure the complexity of the hypothesis space considered by a machine learning algorithm, such as Rademacher complexity, growth function and VC dimension, and discuss mathematical techniques for assessing the qualities of inductive generalisations used by different machine learning algorithms.

The course will be highly mathematical. Explaining lemmas, propositions and theorems and their proofs will form the main part of each lecture. We use multiple mathematical tools, such as concentration inequalities and Fenchel duality, throughout the course. We assume that students do not have any issue in understanding complex mathematical formalisms and proofs, and can construct proofs.

This course is not about state-of-the-art machine learning algorithms and popular recent deep learning models. It is more about well-developed mathematical foundations, which deal mostly with basic traditional machine learning algorithms and concepts. So, if a student is interested in deep learning or other fashionable machine-learning techniques, we advise the student to take a different course targeted at such topics.

## 1. Important Announcements

## 2. Logistics

#### Evaluation

* Homework (40%). Final exam (40%). Critical review (20%).

#### Teaching Staffs

* Lecturer: [Prof Hongseok Yang](https://cs.kaist.ac.kr/people/view?idx=552&kind=faculty&menu=160) (email: hongseok00@gmail.com, office hour: 6:00pm - 7:00pm Monday in ZOOM. You can find more information about it in KLMS.)
* TA: Sangho Lim (email: lim.sang@kaist.ac.kr, office hour: to be announced. You can find more information about it in KLMS.)

#### Place and Time

* Place: ZOOM.
* Lectures: 9:00am - 10:15am on Tuesday and Thursday.

#### Online Discussion

* We will use KLMS.

## 3. Homework

## 4. Tentative Plan

For each chapter we cover in the course, except the last, we plan to have one Q&A session where we discuss questions from students and solve exercise problems in the textbook together. However, if we are far behind the schedule, we may skip some of these Q&A sessions.

* 08/31(Tue) - Introduction. The PAC learning framework (Ch2).
* 09/02(Thu) - The PAC learning framework (Ch2).
* 09/07(Tue) - The PAC learning framework (Ch2).
* 09/09(Thu) - __**[Q&A]**__ The PAC learning framework (Ch2).
* 09/14(Tue) - Rademacher complexity and VC dimension (Ch3).
* 09/16(Thu) - Rademacher complexity and VC dimension (Ch3).
* 09/21(Tue) - __**NO ZOOM MEETING.**__ National holiday (Chuseok).
* 09/23(Thu) - Rademacher complexity and VC dimension (Ch3).
* 09/28(Tue) - __**[Q&A]**__ Rademacher complexity and VC dimension (Ch3).
* 09/30(Thu) - Model selection (Ch4).
* 10/05(Tue) - Model selection (Ch4).
* 10/07(Thu) - __**[Q&A]**__ Model selection (Ch4).
* 10/12(Tue) - Support vector machine (Ch5).
* 10/14(Thu) - Support vector machine (Ch5).
* 10/19(Tue), 10/21(Thu) - __**NO ZOOM MEETING.**__ Midterm exam period.
* 10/26(Tue) - Support vector machine (Ch5).
* 10/28(Thu) - __**[Q&A]**__ Support vector machine (Ch5).
* 11/02(Tue) - Kernel methods (Ch6).
* 11/04(Thu) - Kernel methods (Ch6).
* 11/09(Tue) - Kernel methods (Ch6).
* 11/11(Thu) - __**[Q&A]**__ Kernel methods (Ch6).
* 11/16(Tue) - Regression (Ch11).
* 11/18(Thu) - Regression (Ch11).
* 11/23(Tue) - Regression (Ch11).
* 11/25(Thu) - __**[Q&A]**__ Regression (Ch11).
* 11/30(Tue) - Maximum entropy models (Ch12).
* 12/02(Thu) - __**NO ZOOM MEETING.**__ Undergraduate interview.
* 12/07(Thu) - Maximum entropy models (Ch12).
* 12/09(Thu) - Maximum entropy models (Ch12).
* 12/14(Thu), 12/16(Thu) - __**NO ZOOM MEETING.**__ Final exam period.

## 5. Critical Review

## 6. Study Materials

We will closely follow the textbook "Foundations of Machine Learning" (second edition) by Mohri, Rostamizadeh, and Talwalkar. The webpage of the textbook contains many useful materials, including the HTML version of the book and the list of typos.

* Main Textbook: [Foundations of Machine Learning (2nd edition)](https://cs.nyu.edu/~mohri/mlbook/).

